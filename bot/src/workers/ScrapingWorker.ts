import { Queue, Worker, Job } from 'bullmq';
import IORedis from 'ioredis';
import * as cron from 'node-cron';
import { LeboncoinScraper } from '../scraper/LeboncoinScraper';
import { DatabaseConfig, ScrapingJobData, RedisConfig } from '../types';

/**
 * Worker de scraping avec syst√®me de jobs BullMQ
 * 
 * Ce module g√®re l'ex√©cution asynchrone des jobs de scraping avec :
 * - Queue Redis pour la persistance
 * - Cron job automatique
 * - Retry automatique avec backoff
 * - Monitoring des jobs
 */
export class ScrapingWorker {
  private redisConnection: IORedis;
  private scrapingQueue: Queue<ScrapingJobData>;
  private scrapingWorker: Worker<ScrapingJobData>;
  private dbConfig: DatabaseConfig;
  private isRunning: boolean = false;

  constructor(dbConfig: DatabaseConfig, redisConfig: RedisConfig) {
    this.dbConfig = dbConfig;
    
    // Configuration Redis
    this.redisConnection = new IORedis({
      host: redisConfig.host,
      port: redisConfig.port,
      maxRetriesPerRequest: 3,
    });

    // Queue pour les jobs de scraping
    this.scrapingQueue = new Queue<ScrapingJobData>('scraping-jobs', {
      connection: this.redisConnection,
      defaultJobOptions: {
        removeOnComplete: 10, // Garder seulement les 10 derniers jobs termin√©s
        removeOnFail: 50,     // Garder les 50 derniers jobs √©chou√©s
        attempts: 3,          // 3 tentatives maximum
        backoff: {
          type: 'exponential',
          delay: 2000,
        },
      },
    });

    // Worker pour traiter les jobs
    this.scrapingWorker = new Worker<ScrapingJobData>(
      'scraping-jobs',
      this.processScrapingJob.bind(this),
      {
        connection: this.redisConnection,
        concurrency: 1, // Un seul job √† la fois pour √©viter la surcharge
      }
    );

    this.setupEventHandlers();
  }

  /**
   * Configure les gestionnaires d'√©v√©nements du worker
   */
  private setupEventHandlers(): void {
    this.scrapingWorker.on('completed', (job) => {
      console.log(`‚úÖ Job ${job.id} termin√© avec succ√®s`);
    });

    this.scrapingWorker.on('failed', (job, err) => {
      console.error(`‚ùå Job ${job?.id} √©chou√©:`, err.message);
    });

    this.scrapingWorker.on('error', (err) => {
      console.error('üí• Erreur du worker:', err);
    });
  }

  /**
   * Traite un job de scraping
   * @param job Job √† traiter
   * @returns R√©sultat du job
   */
  private async processScrapingJob(job: Job<ScrapingJobData>) {
    const { searchUrl, maxPages, jobId } = job.data;
    
    console.log(`üöÄ D√©but du job de scraping ${jobId}`);
    console.log(`üìã URL: ${searchUrl}`);
    console.log(`üìÑ Pages max: ${maxPages}`);

    const scraper = new LeboncoinScraper(this.dbConfig);
    
    try {
      await scraper.initialize();
      
      const listings = await scraper.scrapeSearchResults(searchUrl, maxPages);
      console.log(`üìä ${listings.length} annonces trouv√©es`);
      
      const { saved, skipped } = await scraper.saveListingsToDatabase(listings);
      
      console.log(`‚úÖ Job ${jobId} termin√©:`);
      console.log(`   - Annonces sauvegard√©es: ${saved}`);
      console.log(`   - Annonces ignor√©es: ${skipped}`);
      
      return { saved, skipped, total: listings.length };
      
    } catch (error) {
      console.error(`‚ùå Erreur dans le job ${jobId}:`, error);
      throw error;
    } finally {
      await scraper.close();
    }
  }

  /**
   * Programme un job de scraping
   * @param searchUrl URL de recherche
   * @param maxPages Nombre maximum de pages
   * @returns ID du job programm√©
   */
  async scheduleScrapingJob(searchUrl: string, maxPages: number = 2): Promise<string> {
    const jobId = `scraping-${Date.now()}`;
    
    await this.scrapingQueue.add(
      'scrape-leboncoin',
      {
        searchUrl,
        maxPages,
        jobId
      },
      {
        jobId,
        delay: 0, // Ex√©cution imm√©diate
      }
    );
    
    console.log(`üìÖ Job de scraping programm√©: ${jobId}`);
    return jobId;
  }

  /**
   * Configure le cron job automatique
   * @param cronExpression Expression cron (d√©faut: toutes les 10 minutes)
   * @param searchUrls URLs de recherche √† scraper
   */
  setupCronJob(cronExpression: string = '*/10 * * * *', searchUrls: string[]): void {
    console.log('üïê Configuration du cron job...');
    console.log(`‚è∞ Expression: ${cronExpression}`);

    cron.schedule(cronExpression, async () => {
      console.log('‚è∞ D√©clenchement du cron job de scraping');
      
      for (const url of searchUrls) {
        try {
          await this.scheduleScrapingJob(url, 2); // 2 pages par recherche
          // Petit d√©lai entre les jobs pour √©viter la surcharge
          await new Promise(resolve => setTimeout(resolve, 5000));
        } catch (error) {
          console.error(`‚ùå Erreur lors de la programmation du job pour ${url}:`, error);
        }
      }
    }, {
      timezone: "Europe/Paris"
    });
  }

  /**
   * Obtient les statistiques de la queue
   * @returns Statistiques des jobs
   */
  async getQueueStats() {
    const waiting = await this.scrapingQueue.getWaiting();
    const active = await this.scrapingQueue.getActive();
    const completed = await this.scrapingQueue.getCompleted();
    const failed = await this.scrapingQueue.getFailed();

    return {
      waiting: waiting.length,
      active: active.length,
      completed: completed.length,
      failed: failed.length
    };
  }

  /**
   * D√©marre le worker
   */
  async start(): Promise<void> {
    if (this.isRunning) {
      console.log('‚ö†Ô∏è Worker d√©j√† en cours d\'ex√©cution');
      return;
    }

    console.log('üöÄ D√©marrage du worker de scraping...');
    console.log('üìä Queue BullMQ configur√©e');
    console.log('üîÑ Worker en attente de jobs...');
    
    this.isRunning = true;

    // Gestion de l'arr√™t propre
    process.on('SIGINT', async () => {
      console.log('üõë Arr√™t du worker...');
      await this.stop();
      process.exit(0);
    });
  }

  /**
   * Arr√™te le worker
   */
  async stop(): Promise<void> {
    if (!this.isRunning) {
      return;
    }

    console.log('üõë Arr√™t du worker...');
    await this.scrapingWorker.close();
    await this.scrapingQueue.close();
    await this.redisConnection.quit();
    this.isRunning = false;
  }

  /**
   * V√©rifie si le worker est en cours d'ex√©cution
   */
  isActive(): boolean {
    return this.isRunning;
  }
}
