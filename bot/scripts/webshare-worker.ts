/**
 * Worker principal pour le scraping continu de Leboncoin avec proxies Webshare
 * 
 * Ce fichier d√©marre le worker avec les proxies Webshare pour contourner
 * la protection anti-bot de Leboncoin
 */

import { WebshareLeboncoinScraper } from '../src/scraper/WebshareLeboncoinScraper';
import { DatabaseManager } from '../src/database/DatabaseManager';
import { DatabaseConfig } from '../src/types';
import * as cron from 'node-cron';

/**
 * Configuration par d√©faut
 */
const defaultDbConfig: DatabaseConfig = {
  host: process.env.DB_HOST || 'localhost',
  port: parseInt(process.env.DB_PORT || '5432'),
  database: process.env.DB_NAME || 'marketplace',
  user: process.env.DB_USER || 'postgres',
  password: process.env.DB_PASSWORD
};

/**
 * URLs de recherche par d√©faut
 */
const defaultSearchUrls = [
  'https://www.leboncoin.fr/recherche?category=17&text=iphone%2013&phone_memory=128go',
  'https://www.leboncoin.fr/recherche?category=17&text=iphone%2014&phone_memory=128go',
  'https://www.leboncoin.fr/recherche?category=17&text=iphone%2015&phone_memory=128go'
];

/**
 * Expression cron par d√©faut (toutes les 10 minutes)
 */
const defaultCronExpression = '*/10 * * * *';

/**
 * Classe Worker avec proxies Webshare
 */
class WebshareScrapingWorker {
  private scraper: WebshareLeboncoinScraper;
  private dbManager: DatabaseManager;
  private isRunning: boolean = false;
  private cronJob: cron.ScheduledTask | null = null;

  constructor(dbConfig: DatabaseConfig) {
    this.scraper = new WebshareLeboncoinScraper();
    this.dbManager = new DatabaseManager(dbConfig);
  }

  /**
   * D√©marre le worker
   */
  async start(): Promise<void> {
    console.log('üöÄ D√©marrage du worker de scraping avec proxies Webshare...');
    
    try {
      // Initialiser la base de donn√©es
      await this.dbManager.initialize();
      console.log('‚úÖ Base de donn√©es initialis√©e');
      
      // Tester les proxies Webshare
      console.log('üß™ Test des proxies Webshare...');
      const proxyStats = this.scraper.getProxyStats();
      console.log(`üìä Proxies disponibles: ${proxyStats.active}/${proxyStats.total} (${proxyStats.successRate}% succ√®s)`);
      
      if (proxyStats.active === 0) {
        console.log('‚ö†Ô∏è Aucun proxy disponible, utilisation directe');
        this.scraper.setUseProxies(false);
      }
      
      this.isRunning = true;
      console.log('‚úÖ Worker d√©marr√© avec succ√®s');
      
    } catch (error) {
      console.error('‚ùå Erreur lors du d√©marrage du worker:', error);
      throw error;
    }
  }

  /**
   * Configure le cron job automatique
   */
  setupCronJob(cronExpression: string, searchUrls: string[]): void {
    console.log(`‚è∞ Configuration du cron job: ${cronExpression}`);
    
    this.cronJob = cron.schedule(cronExpression, async () => {
      console.log('üîÑ Ex√©cution du cron job...');
      await this.executeScrapingJob(searchUrls);
    });
    
    console.log('‚úÖ Cron job configur√©');
  }

  /**
   * Ex√©cute un job de scraping
   */
  async executeScrapingJob(searchUrls: string[]): Promise<void> {
    console.log(`üîç D√©but du scraping de ${searchUrls.length} URLs...`);
    
    let totalListings = 0;
    let totalErrors = 0;
    
    for (const url of searchUrls) {
      try {
        console.log(`\nüìÑ Scraping: ${url}`);
        
        // Scraper avec proxies Webshare
        const listings = await this.scraper.scrapeSearchResultsWithWebshareProxy(url, 2);
        
        if (listings.length > 0) {
          console.log(`‚úÖ ${listings.length} annonces trouv√©es`);
          
          // Sauvegarder en base de donn√©es
          for (const listing of listings) {
            try {
              await this.dbManager.saveListing(listing);
              totalListings++;
            } catch (dbError) {
              console.error('‚ùå Erreur lors de la sauvegarde:', dbError);
              totalErrors++;
            }
          }
        } else {
          console.log('üì≠ Aucune annonce trouv√©e');
        }
        
        // Attendre entre les URLs
        await new Promise(resolve => setTimeout(resolve, 5000));
        
      } catch (error) {
        console.error(`‚ùå Erreur lors du scraping de ${url}:`, error);
        totalErrors++;
      }
    }
    
    console.log(`\nüéâ Scraping termin√©: ${totalListings} annonces sauvegard√©es, ${totalErrors} erreurs`);
    
    // Afficher les statistiques des proxies
    const proxyStats = this.scraper.getProxyStats();
    console.log(`üìä Statistiques proxies: ${proxyStats.active}/${proxyStats.total} actifs (${proxyStats.successRate}% succ√®s)`);
  }

  /**
   * Arr√™te le worker
   */
  async stop(): Promise<void> {
    console.log('üõë Arr√™t du worker...');
    
    if (this.cronJob) {
      this.cronJob.stop();
      this.cronJob = null;
    }
    
    this.isRunning = false;
    await this.dbManager.close();
    
    console.log('‚úÖ Worker arr√™t√©');
  }

  /**
   * V√©rifie si le worker est actif
   */
  isActive(): boolean {
    return this.isRunning;
  }

  /**
   * Obtient les statistiques des proxies
   */
  getProxyStats() {
    return this.scraper.getProxyStats();
  }

  /**
   * Obtient les statistiques de la base de donn√©es
   */
  async getDatabaseStats() {
    try {
      const stats = await this.dbManager.getStats();
      return stats;
    } catch (error) {
      console.error('‚ùå Erreur lors de la r√©cup√©ration des stats DB:', error);
      return null;
    }
  }
}

/**
 * Fonction principale
 */
async function main() {
  console.log('üöÄ D√©marrage du worker de scraping ScanLeCoin avec proxies Webshare...');
  
  try {
    // Cr√©er le worker
    const worker = new WebshareScrapingWorker(defaultDbConfig);
    
    // Configurer le cron job automatique
    worker.setupCronJob(defaultCronExpression, defaultSearchUrls);
    
    // D√©marrer le worker
    await worker.start();
    
    console.log('‚úÖ Worker d√©marr√© avec succ√®s');
    console.log('‚è∞ Cron job configur√© (toutes les 10 minutes)');
    console.log('üîÑ En attente de jobs...');
    
    // Garder le processus en vie et afficher les stats
    setInterval(async () => {
      if (worker.isActive()) {
        const proxyStats = worker.getProxyStats();
        const dbStats = await worker.getDatabaseStats();
        
        console.log(`üìä Stats: ${proxyStats.active}/${proxyStats.total} proxies actifs (${proxyStats.successRate}% succ√®s)`);
        if (dbStats) {
          console.log(`üìä DB: ${dbStats.totalListings} annonces, ${dbStats.totalSellers} vendeurs, ${dbStats.totalLocations} localisations`);
        }
      }
    }, 60000); // Afficher les stats toutes les minutes
    
    // Gestion propre de l'arr√™t
    process.on('SIGINT', async () => {
      console.log('\nüõë Signal d\'arr√™t re√ßu...');
      await worker.stop();
      process.exit(0);
    });
    
    process.on('SIGTERM', async () => {
      console.log('\nüõë Signal de terminaison re√ßu...');
      await worker.stop();
      process.exit(0);
    });
    
  } catch (error) {
    console.error('‚ùå Erreur lors du d√©marrage du worker:', error);
    process.exit(1);
  }
}

// Ex√©cuter si ce fichier est appel√© directement
if (require.main === module) {
  main().catch(console.error);
}
